\begin{abstract}
This project proposes and implements a near real-time vision processing framework on the \textit{Bumblebee AUV (Autonomous Underwater Vehicle)} that participates in Robosub, an international autonomous robotics submarines held annually in San Diego hosted by AUVSI (Association for Unmanned Vehicle Systems International).

The implemented vision system will be deployed on the AUV to complete a series of visual tasks during the competition that mimics real world underwater application such as collecting data on marine life-forms, repairing underwater pipeline etc. Though there are many state-of-the-art vision algorithms developed by the community, the underwater domain poses an entirely different set of challenges such as low contrast, color degradation and underwater perturbations that demands a different vision processing approach.

The primary contribution of the project is to implement a vision framework consisting of a set of modular vision modules and pipelines for real-time object tracking in different underwater conditions. It is essential that the the vision framework is both a) adaptive, b) robust and c) easy to use. With the implemented vision modules, the project's secondary contribution aims to automate parameter selection and model selection; taking the human out of the loop.

\begin{descriptors}
    \item Computer System Implementation
    \item Visual Computing
\end{descriptors}
\begin{implement}
    Python, ROS (Robot Operating System)
\end{implement}
\end{abstract}

\begin{acknowledgement}
    I would like to acknowledge the advice and guidance by my supervisor Prof. Terrence Sim Mong Cheng in this project.
\end{acknowledgement}
