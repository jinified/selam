\chapter{Literature Review}
This review is conducted with the purpose to investigate and select most suitable algorithms that generate the best result on the Robosub datasets. Since every teams who participate in Robosub are required to submit a journal paper,vision algorithms deployed by top-peforming schools such as Cornell University, University of Florida and École de technologie supérieure provide valuable insights on image processing that are effective in underwater environment. Besides that, review of popular image processing techniques in particular on topics like object detection, object tracking, color constancy, saliency mechanism, detection proposals and adapatation of algorithms.

\section{Preprocessing}
\subsection{Underwater Image Enhancement}
The paper by \outcite{garcia2002way} compared methods such as homomorphic filtering and local adaptive histogram equalization (Contrast Limited Adaptive Histogram) which considers that image is a product of illumination and reflectance properties. However, homomorphic filter has the benefit of preserving sharp edges while attenuating non-uniform illumination. On the other hand, by only redistributing pixels exceeding a clipping level to increase contrast of an image, CLAHE manages to reduce noise amplification in normal local histogram equalization.

Instead of relying on a single image, \outcite{Gracias2008} recover corrupted underwater image by finding the difference between the current frame with temporal median of a registered set of N frames. Image dehazing is equally as important to ensure good performance of further image processing operation such feature detection. \outcite{Kaiming2011} proposed a single image dehazing method using the dark channel prior which states that haze-free image contains local region with low intensities in at least one color channel. \outcite{Galdran2015} propose a variant of dark channel prior for underwater environment, the Red Channel method as red color shows most degradation in turbid water medium. From another perspective, \outcite{Ancuti2011} takes a fusion-approach to recover the original image by generating a few weight maps that correlates with intrinsic properties of the image itself. A color corrected and contrast enhanced of the input image are used to generate different weight maps that are fused using a Laplacian multi-scale strategy to generate a smoothed output image. This method has the benefit of using a single image but the weight maps must be combined with different weightage to achieve an ideal result. 

\subsection{Color Constancy}
Color cue plays an important role to distinguish different objects such as the small cylinders in Robosub that requires sorting by color. The ability to account for color of the light source is called color constancy. The work of \outcite{Gijsenij2011} analyzes various color constancy algorithms. Attention is paid especially on low-level statistics methods that are computationally inexpensive compared to learning-based methods. The Grey-World \cite{buchsbaum1980spatial} estimate the color of the light source by estimating the average color in the image assuming that any deviation from average color (Grey) is caused by illuminants. The White-Patch method \cite{land1977retinex} estimates the color of light source by computing the maximum response in individual RGB color channels. \outcite{finlayson2004shades} shows that both Grey-World and White-Patch algorithms are special instantiation of a more general color constancy algorithm based on Minkowski norm called Shades of Grey. Their investigation of best illumination estimation suggests using Minkowski norm, p = 6 to obtain optimal performance.

Though we see new method such as the Color Rabbit \cite{Bani??2014} which combine multiple local illumination estimations to a global one, these class of methods are more computationally expensive which is not suitable for real-time application. Inspired by primary visual cortex (V1) of human visual system (HVS), \outcite{Gao2013} estimate the true illuminant color of a scene by computing the maximum response in separate RGB channels of the responses of double-opponent cells. This method is shown to perform better on outdoor scenes from Gehler-Shi dataset where the mean reflectance is not achromatic which is assumed by Grey-World based methods. 

\section{Saliency Region Detection}
Ability of human visual system (HVS) to selectively process only the salient visual stimuli, specifically salient object detection helps to reduce computation time of object recognition that traditionally relies of sliding-window approach to detect object of interest. \outcite{achanta2009frequency} estimate centre-surround contrast using color and luminance features using a frequency-tuned approach to generate high-resolution saliency map. In contrast, biological inspired method of \cite{Itti1998} that computes centre-surround contrast using Difference of Gaussian (DoG) which generates low resolution map and ill-defined boundaries because of down sampling of original image.Because saliency detection often work poorly in low contrast environment i.e underwater environment, work of \outcite{VanDeWeijer2005} boost local color information by analyzing isosalient colour derivatives. \outcite{Cao2010} extended work of Van de Weijer as Gaussian derivatives of each opponent color to get a better iso-salient transformation. 

\section{Detection Proposals}
Relying on saliency mechanism is insufficient in perturbed underwater condition; therefore, different detection proposals algorithms are investigated. \outcite{Hosang2015} cited that "detection proposals" which can be grouped into a) grouping proposal methods and b) Window scoring proposals methods are used extensively by top performing object detectors in PASCAL and ImageNet. On top of reduced computation cost by avoiding exhaustive sliding window approach, detection proposals improve recall by filtering out false positives. Recent work of \outcite{Winschel2016} combines top performing detection proposals methods, SelectiveSearch \cite{uijlings2013selective} and EdgeBox \cite{zitnick2014edge}. Though detection proposals allow for faster object recognition, it is important that it does not filter out object of interest and incur more computation costs that out weights time saved.

\section{Object Detection and Tracking}
An overall review of journal papers submitted by top-performing teams in Robosub shows a general trend of combining surprisingly simple computer vision techniques such as adaptive color thresholding, edge detection i.e Canny Edge \cite{canny1986computational}, and contour analysis i.e Hu moment \cite{hu1962visual}. Team CUAUV (Cornell AUV) proposes adaptive color thresholding on different color spaces such as LAB, LUV and YCrCb where the individual masks are combined to form final binarized mask. This is a blob-based detection approach where contour generated by OpenCV's implementation of  \cite{suzuki1985topological}  will be matched against known geometric properties of desired object of interest. \outcite{Walters2014} use particle filter approach to detect and track object of interest. Known for its ability to deal with non-linear noise and multi-modal hypotheses \cite{isard1998condensation}, particle filter has the ability to recover from wrongly tracked objects. Though more sophisticated techniques such as neural-network classification is deployed, teams still generally rely on low-level visual cues such as color and edge. This may be attributed to simplicity and efficiency of mentioned algorithms. \outcite{Benoit2014} 
focuses on developing sophisticated vision tuning client that allows for rapid prototyping via "mix and match" approach to design a suitable vision pipeline for each individual vision tasks.
