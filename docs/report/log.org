* Feb: Week 3: *13-19*
** Smarter image annotation [[file:~/github/selam/examples/meanshift_annotator.py][Source]]
Convert to LAB colorspace and apply meanshift on initialized bounding box. Camshift does not 
work as well as changing the scale seems to include too much of the background. Shade of grey is applied
to normalize the color
** Data Preprocessing <2017-02-18 Sat>
*** [[https://stackoverflow.com/questions/21370087/how-to-preprocess-data-for-machine-learning][How to preprocess data for machine learning]]
*** [[https://www.datacamp.com/community/tutorials/the-importance-of-preprocessing-in-data-science-and-the-machine-learning-pipeline-i-centering-scaling-and-k-nearest-neighbours#gs.eE=F3Pk][Importance of preprocessing]]
**** Feature scaling / normalization to certain range  is important to ensure equal weights and unit-independent
**** Feature standardization centering the data around 0 and scale according to standard deviation
**** Should not be done blindly if there is significance in the scale of the data
**** Samplewise normalization can be important as it imitates how our human vision works
**** Using small image size for training helps
**** Can explore using gradient information for training also
*** [[http://ufldl.stanford.edu/wiki/index.php/Data_Preprocessing][Stanford Unsupervised Feature Learning Preprocessing]] 
*** [[http://mccormickml.com/2014/06/03/deep-learning-tutorial-pca-and-whitening/][More about whitening]]
**** First decorrelate data by projecting to eigenvectors
**** Normalize to have same variance by dividing by square root of eigenvalues
*** TODO [[http://ufldl.stanford.edu/wiki/index.php/Whitening][Whitening]] aims to remove redundancy since adjacent pixels are similar with large epsilon
*** Avoid example-wise normalization if color image since distribution not stationary for different channels
*** Rescale pixel values to [0 - 1] for numerical stability and work with higher precision
*** Be careful when choosing size of image as too large will increase the weight for the DNN 
*** [[https://stats.stackexchange.com/questions/117427/what-is-the-difference-between-zca-whitening-and-pca-whitening][Choosing between PCA or ZCA whitening]] 
*** *AVOID* PCA Whitening when image too big since covariance matrix will be too big 
*** [[http://eric-yuan.me/ufldl-exercise-pca-image/][Implementation of PCA Whitening 
*** ]][[https://gist.github.com/JBed/5673060beac474805e38][Implementation of 1 / f whitening for large images]] 
*** [[https://stackoverflow.com/questions/31528800/how-to-implement-zca-whitening-python][UFDL Solution for Whitening]]
**** Must zero mean example wise for whitening 
** Data Augmentation <2017-02-18 Sat>
*** [[https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html][Keras Data Augmentation to work with little data]]  
*** TODO [[http://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html][Fancy PCA]]
**** alters intensity of RGB levels used in AlexNet to capture invariance of object to illumination [[https://stats.stackexchange.com/questions/251892/implementing-fancy-pca-augmentaiton][Possible implementation]]
*** Color jittering (chaning some values of saturation and value within a range)
*** TODO Cropping smaller patches of images while keeping aspect-ratios
** Limit with scikit-learning <2017-02-18 Sat>
*** [[http://scikit-learn.org/stable/modules/scaling_strategies.html][Scaling strategies]]
*** Need to do incremental learning to prevent out of memory error
*** [[http://scikit-learn.org/stable/developers/performance.html][Improve performance by profiling your code. Scikit-learn]] 
** Batch-Normalization <2017-02-19 Sun>
*** [[https://www.youtube.com/watch?v=gYpoJMlgyXA&feature=youtu.be&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&t=3078][CS231n: Batch-Normalization]] 
Basically, zero mean unit variance on mini-batch to ensure unit gaussian. Extra step where each feature allowed to, shift by certain constant.
Network can essentially recover its original values where \[x' = normalized(x) * y + k\] where $y can be the standard deviation and 
$k can be the mean. It will recover its identity
*** [[https://www.quora.com/How-should-input-data-be-normalized-when-training-an-SVM-with-an-online-algorithm][Batch-Normalization for online SVM]]
Buffer the examples as they come in to get an estimate of the mean and standard deviation 
*** [[https://arxiv.org/pdf/1305.6646.pdf][Normalizing Online Algorithms]] 
** Object Proposals <2017-02-19 Sun>
*** [[https://github.com/dculibrk/edge_boxes_with_python][Python Wrapper Edge Boxes]]
*** [[https://github.com/pdollar/toolbox][Piotr Dollar Matlab Toolbox]] 
* Feb: Week 4: *20-26*
** Object Proposals <2017-02-20 Mon>
*** Edge Box does not seemed to work well because of lack of clear edges
*** [[https://github.com/torrvision/Objectness][BING: Objectness Estimation at 300 FPS]] [[http://mmcheng.net/mftp/Papers/ObjectnessBING.pdf][Original paper]]
**** Resized image into multiple quantized size (8 x 8)
**** Calculate norm gradient and its binarized form (Binarized Norm Gradient, BING)
**** Insensitive to scaling, translation and aspect ration because whole image is used
*** [[https://github.com/AlpacaDB/selectivesearch][Selective Search]]  [[http://koen.me/research/pub/vandesande-iccv2011.pdf][Original paper]]
**** Rely on segmentation and it is very slow.
**** Hierarchical search using size and appearance features in all scales. Then greedily combine them
**** Uses Hue color space as most insensitive to shadow and shading as base for segmentation
**** HOG: OpponentSIFT and RGB-SIFT 
** Hard Negative Mining <2017-02-20 Mon>
*** Generate a bunch of random patches that does not overlap with bounding box as negative examples
*** Using false positive as negative examples in subsequent training
** Determine an appropriate tracking methodoloy <2017-02-20 Mon>
*** [[https://pdfs.semanticscholar.org/e2b0/daf08b5fb360c15894b05b354b66ddb2a27f.pdf][Compare PSO and Particle Filter]] PSO is slower and cannot handle local occlusions as well 
** How to compare different classification algorithms ? <2017-02-20 Mon>
*** [[https://www.researchgate.net/publication/237145103_Data_analysis_advances_in_marine_science_for_fisheries_management_Supervised_classification_applications][Comparing algorithm using paired-t test]]
*** [[http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf][Comparison of different classifiers]]
Random Forest requires more data but not much tuning of parameters compared to SVM. SVM works well with 
small datasets with few outliers. 
** Measuring quality of an image
*** [[http://neelj.com/projects/lbiq/576_iqa.pdf][Learning a blind measure of image quality]]
Just need to ensure that the raw image is not too terrible
* Mar: Week 8: *6-12*
** Setting up Python project
*** tests, docs, setup.py (using setuptools)
*** versioneer to link git tag to version number in setup.py
** MSER object detection <2017-03-08 Wed>
*** Works well using Saturation channel if there is distinct color
** Encoding shape
*** Shape descriptor often considered global descriptor which allows for only object classfication
*** [[http://www.ijcsits.org/papers/vol3no12013/9vol3no1.pdf][Survey of Shape Descriptors]] 
*** [[https://www.math.uci.edu/icamp/summer/research_11/park/shape_descriptors_survey_part3.pdf][Shape Descriptors Techniques]]
** Diagnosing bias vs variance <2017-03-08 Wed>
*** Plotting the training error and cross-validation error
*** Bias: high training and cross-validation error
*** Variance: low training and high cross-validation error
* Mar: Week 9: *12-20*
** Color constancy implementation <2017-03-13 Mon>
*** Still have some issue when using an image with large size (weird patches)
*** Statistical methods work very well
** Object Proposals
*** Edge boxes needed to be trained on specific training classes to be more effective
*** FASA (Fast Accurate Size Aware) saliency does not work well for underwater images
*** MSER worked best among the object proposals algorithm
*** Resources:
**** [[https://www.robots.ox.ac.uk/~vgg/rg/papers/hosang_pami15.pdf][What Makes Effective Object Proposals ?]] 
***** Grouping method (Superpixel, Graph Cut, Edge Contour). Higher accuracy
***** Window method (score candidate window). Need to have dense window for high accuracy. Faster 
***** Repeatability potential
****** Generate several pertubated versions (blur, illumination, rotation, scale)
****** BING works well for small scale changes
****** Illumination affects those that rely on superpixel
****** WINNER: BING and EdgeBox uses SVM for scoring and random forest for feature computation
***** Recall potential
****** WINNER: SelectiveSearch, EdgeBox, Geodesic
**** [[http://vision.unipv.it/CV/materiale2016-17/4th%20Choice/0014.pdf][Comprehensive survey of object proposal methods for vehicle detection]] 
**** [[http://rodrigob.github.io/documents/2014_bmvc_selective_search_with_supplementary_material.pdf][How Good Are Object Proposals ? ]] 
**** [[http://homes.cs.washington.edu/~shapiro/yao-aaai.pdf][Closing the loop for object proposal]] 
**** [[https://pdollar.wordpress.com/2013/12/22/generating-object-proposals/][PDollar thoughts on effective proposals ?]] 
***** [[http://groups.inf.ed.ac.uk/calvin/objectness/][Objectness]] scores likelihood of containing object using multiple cues such as saliency, edge and superpixel 
***** [[http://vision.cs.uiuc.edu/proposals/][CPMC]] uses graph cut to generate foreground and background separation 
***** [[http://koen.me/research/selectivesearch/][Selective Search]] use hierarchical superpixel segmentation with 8 sec per image
***** [[http://www.vision.ee.ethz.ch/~smanenfr/rp/index.html][Randomized Prim's]] randomized greedy algorithm to generate set of superpixels
**** [[https://pdollar.wordpress.com/2013/12/10/a-seismic-shift-in-object-detection/][A seismic shift in object detection]] 
***** Design better feature (deep learned feature)
***** Use linear SVM instead of parts based model
***** Use segmentation instead of sliding window except for fixed size
**** [[https://github.com/caocuong0306/awesome-object-proposals][Awesome object proposals]] 
**** [[http://mp7.watson.ibm.com/ICCV2015/slides/iccv_hosang.pdf][Region Proposal]]  
*** Experiment with MSER
**** YUV's V color space works well for yellow and green detection
** Object Proposals cont'd <2017-03-17 Fri>
*** Using canny edge and detect inner contours of each contour to simulate effect of edge box
**** [[https://www.quora.com/How-do-I-set-the-upper-and-lower-threshold-in-canny-edge-detection][Determine the best threshold]]
***** Using the mean and scale around it 
***** Using Otsu to give the upper threshold
**** [[http://www.kerrywong.com/2009/05/07/canny-edge-detection-auto-thresholding/][Kerry wong auto threshold]] 
**** [[http://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/][PyImageSearch using median]] 
**** Best color space: HSV and XYZ
*** Using superpixel segmentation with SLIC and SEED workws well too
** Saliency benchmarks. How to make it work for underwater condition ?
*** [[https://github.com/yhenon/pyimgsaliency][Python saliency tools]]
*** [[http://saliency.mit.edu/results_mit300.html][MIT Saliency Benchmark]] 
**** Saliecy model produces saliency value at each pixel tested against human attention
**** Evaluated using 8 different metrics
***** AUC (Area under ROC curve)
****** Receiver Operating Characteristics (ROC) investigate trade off between true and false positives at different threshold
****** ROC curve visualizes all possible thresholds
****** AUC. perfect = 1. random guess = 0.5
****** low value false positive not penalized by AUC
***** Shuffled AUC
****** Compensates for center bias by sampling fixation location of negatives rather than randomly
***** Normalized Scanpath Saliency
****** penalizes false positives
***** Pearson's Correlation Coefficient
***** Earth Mover Distance
***** Histogram intersection
****** affected by blurring of gaussian used when generating saliency map
****** penalizes false negatives
***** KL-divergence
***** Information Gain
**** 
*** [[http://saliency.mit.edu/ECCVTutorial/ECCV_saliency.htm][New direction in saliency research]] 
*** [[https://arxiv.org/pdf/1501.02741.pdf][Salient object detection a benchmark]]
**** Essentially a figure/ground seperation problem
**** Applications: object recognition, video summarization, object discovery, compression
**** Analysis of segmentation methods
***** Fixed threshold, adaptive threshold, saliency cut
**** Handling background images as most algorithms assume some objects there
***** Fixation prediction that produce sparse activation works better like COV and IT
**** Challenges in saliency detection
***** Object size
***** Clutter of background (complex scene)
***** Contrast (similarity to background) 
**** Top performing models
***** [[https://pdfs.semanticscholar.org/13a7/e1b536fc4a57b814ce49aa4082ac3b2e6163.pdf][Saliency Detection via high dimension color transform]]
** Enhancement
*** Dark channel prior does not work well. No difference
*** [[https://www.researchgate.net/post/Can_anyone_help_me_with_enhancing_underwater_images_and_videos_by_fusion][Underwater image enhancement]] 
*** No noticeable difference using [[https://www.youtube.com/watch?v=B_TiVX7zN8U][anisotropic diffusion]]
*** [[https://www.youtube.com/watch?v=3kSW7pzpDvM][Homomorphic filtering]] 
**** Quite effective but slow python implementation
*** [[http://www.ijarcce.com/upload/2016/si/SITES-16/IJARCCE-SITES%2034.pdf][Review Underwater Image 2016]]
**** Homomorphic filter
***** Corrects non-uniform lighting and sharpen image. High frequency consists of true reflectance
**** Anisotropic filter
***** smoothes homogeneous area while shapening edge. done after denoising (homomorphic filter)
***** edge sensitive extension of average filter
**** Wavelet filter
***** suppress noise. does not assume independence of coefficient
**** Adaptive histogram equalization
***** medium scattering and light distortion causes poor visibility
***** Use CLAHE
*** [[https://arxiv.org/pdf/1702.03600.pdf][Underwater Optical Image Processing]]
**** Wavelength compensation methods for sediment scattering
***** dark channel prior
***** wavelenght compensation and dehazing
***** underwater median dark channel
**** Color reconstruction for light absorption
**** Underwater image quality assessment (very important)
***** [[http://ieeexplore.ieee.org/document/7305804/][Human inspired Underwater Image Quality Measure (UiQm)]]
***** [[https://www.researchgate.net/publication/283326087_An_Underwater_Color_Image_Quality_Evaluation_Metric][Underwater Colour Image Quality Evaluation]]
*** [[http://www.iosrjournals.org/iosr-jvlsi/papers/vol6-issue2/Version-1/G0602013033.pdf][Comparative study of various methods for underwater image enhancement]] 
*** [[http://rspublication.com/ijca/2015/june15/19.pdf][A survey on various underwater image enhancement techniques]]
*** [[http://research.ijcaonline.org/volume87/number13/pxc3893743.pdf][2014 survey]]
*** [[https://www.ijarcsse.com/docs/papers/Volume_5/5_May2015/V5I5-0174.pdf][2015 survey]] 
*** Fusion method works great. Need to increase illumination after fusion
** Illumination / Exposure correction (Face detection) inspire a lot of ideas
*** [[https://www.math.utah.edu/~gustafso/s2014/3150/pdeNotes/Artigo_Stockham_01450712.pdf][Logarithm curve brightness correction instead of gamma]]
** Object representation
*** [[http://web.stanford.edu/class/cs331b/][Representation Learning in Computer Vision]]
**** Classic low-level representation
***** [[http://web.eecs.umich.edu/~silvio/teaching/EECS598_2010/slides/09_28_Grace.pdf][Histogram of Gradient]]
***** [[http://web.mit.edu/vondrick/ihog/][HOGles: Visualize Object Detection Feature]]
***** Affine-Sift (exhaustively transform images then apply SIFT)
***** [[http://robotics.szpku.edu.cn/c/reasearch/publication/paper/SMC2009_XiaojiaYu.PDF][GLOH (Global localization orientation histogram)]]
***** [[http://s3.amazonaws.com/academia.edu.documents/1951909/road_sign_detection_and_recognition_by_using_local_energy_based_shaped_histogram_lesh_1.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1489920836&Signature=0Ph9l63pZavzua0naiqWyEJu3Qk%3D&response-content-disposition=inline%3B%20filename%3DRoad_Sign_Detection_and_Recognition_by_u.pdf][Local energy-based shape histogram (LESH)]]
***** [[https://papers.nips.cc/paper/1913-shape-context-a-new-descriptor-for-shape-matching-and-object-recognition.pdf][Shape Context]]
**** 2D / 3D Representation
***** Challenges: illumination, scale, viewpoint, intra-class, deformation, occlusion, background clutter
***** Generative: infer a function that can explain your observations.
****** Bayes, Autoencoder, RBM, LDA
***** Discriminative: infer function that can separate obervations
****** Nearest neighbor
****** Neural Network
****** SVM
****** Structural SVM
****** Boosting
***** How to learn these functions
****** Incremental, prior, level of supervision
***** BoW (Bag of Words)
***** Template-based (truncation, occlusions, deformation)
****** Spatial pyramid matching
****** HOG
***** Part based
****** sparse representation
****** SVM with mixture components
***** Hierarchical
****** Pixels, Pixel grouping, Parts, Object
***** Detect specific instance (don't care about inter-class variability)
***** Object representation = feature + location
***** Unsupervised learning representation
****** sparse coding
****** basic autoencoder
****** rbm
****** Generative Adversarial Network
***** Supervised learning
** 3D Object Recognition based on Image features
*** SIFT, FAST, SURF, Bag of Features, ORB 
** Survey on color, texture and shape features for person re-identification
*** Need to reduce dimension of features using PCA or DCT
*** Gabor, schmid filter useful for illumination variation
*** Populat shape feature representation
**** EHOG Feature context
**** LBP
**** Dense SIFT
*** [[https://www.researchgate.net/publication/220932655_Multi-scale_Color_Local_Binary_Patterns_for_Visual_Object_Classes_Recognition][Multiscale Color LBP]]
*** [[https://arxiv.org/pdf/1410.1035.pdf][Learning Invariant Color Feature]]
** Survey Feature extraction technique
*** angular radial partitioning
*** Shape descriptor
**** Contour global: farthest distance, centroid length, circularity, eccentricity, area
**** Contour structural: chain code
**** Region based
** Moment-based representation
*** Zernike, pseudo-Zernike the best
*** Fourier descriptor
** [[http://machinelearning.wustl.edu/uploads/Main/appearance_based_methods.pdf][Survey of Appearance based methods]]
*** Corner-based for image with a lot of edge
*** Region-based suited for uniform region
**** Hessian and Harris-Affine
**** Difference of Gaussian (DoG)
**** Entropy-based salient region detector (slow)
**** Edge-based region detector (EBR) (slow)
*** Region of interest descriptor
**** PCA-SIFT, LBP, SIFT, GLOH, Shape Context, Spin Image
*** Moment-based
**** Color moment, Gradient moment
*** Subspace method
**** eigenimages
**** robust pca
**** Independent Component Analysis (audio source separation)
**** Linear Fischer Discriminant Analysis (LDA)
** [[Paradigm in visual object tracking]] (important)
*** Model-free tracking: target object not known and camera placement also
*** Tracking with pre-learned object model: fixed object models too generic and hard to distinguish similar object
**** local feature, region feature and temporal feature
*** Adaptive object model: drifting, integrate new data without accumulating error
*** Salient object model: requires stable resolution of object.
** Color Learning and Illumination Invariance on Mobile Robots: A Survey
*** Color Segmentation
**** Non-parametric
***** [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.8968&rep=rep1&type=pdf][Mean Shift]]
***** [[https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf][Normalized cut]]
**** Active contour: parametric active contour (PAC) and geometric active contour (GAC) 
***** [[http://www.dtic.upf.edu/~vcaselles/papers_v/GAC_article.pdf][Geodesic Active Contour]]
***** [[https://vision.ece.ucsb.edu/sites/vision.ece.ucsb.edu/files/publications/03ICIPBaris.pdf][Image Segmentation using Multi-region stability and edge strength]]
**** Graph-partioning [29, 45, 80]: normalized cut
***** [[https://cs.brown.edu/~pff/papers/seg-ijcv.pdf][Efficient Graph Based Image Segmentation]]
**** Color-map
***** [[https://pdfs.semanticscholar.org/e7f2/b90a9d78d43f38a06ebc011d7ee9f219c9e1.pdf][Real time vision on mobile robot platform]]
*** Color Learning [39, 57, 85, 49, 83, 84]
**** [[http://nichol.as/papers/Gevers/Color-based%20object%20recognition.pdf][Color based object recognition]]
**** [[http://isl.ecst.csuchico.edu/DOCS/darpa2005/DARPA%202005%20Stanley.pdf][The Robot that won the Darpa Grand Challenge]]
**** [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.5748&rep=rep1&type=pdf][Using Layered Color Precision for a self-calibrating vision system]]
**** [[https://pdfs.semanticscholar.org/c3d9/ef37adf2e1bc3fcb6c8c1046fd53f2a697f4.pdf][Autonomous Color Learning on Mobile Robot]]
*** Illumination Invariance
**** [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.103&rep=rep1&type=pdf][A Novel Algorithm for Color Constancy Gamut Mapping]]
**** [[http://www.cs.cmu.edu/~mmv/papers/03icra-scott.pdf][Automatic detection and response to environmental change]]
**
* Mar: Week 10: *21-26*
** Shape Descriptors
*** [[http://www.cs.umd.edu/~djacobs/pubs_files/ID-pami-8.pdf][Shape Classification using inner distance]]
*** [[http://eeeweba.ntu.edu.sg/computervision/Research%20Papers/2016/Invariant%20Multi-Scale%20Shape%20Descriptor%20for%20Object%20Matching%20and%20Recognition.pdf][Invariant Multi-scale Descriptors (IMD)]] (best)
*** [[https://www.researchgate.net/profile/Luis_Sucar/publication/269334651_LISF_An_invariant_local_shape_features_descriptor_robust_to_occlusion/links/54ed8c6f0cf28f3e6535a238/LISF-An-invariant-local-shape-features-descriptor-robust-to-occlusion.pdf][LISF: Invariant Local Shape Descriptor]]
**** Region based like zernike, legrende and fourier lack discrminative power
**** [[https://pdfs.semanticscholar.org/807a/418a129828bad4ab1946f387ad27c0571977.pdf][Generic Fourier Descriptor]]
**** [[http://repository.um.edu.my/2538/1/Translation%20and%20scale%20invariants%20of%20Legendre%20moments.pdf][Legrende Moment]]
*** [[https://github.com/torrvision/straighttoshapes][Straight to Shape]]
**** Learning a shape embedding using autoencoder
*** [[http://www.image.ece.ntua.gr/courses_static/dip/advanced/material/retrieval/Curvature%20scale%20space%20image%20in%20shape%20similarity%20retrieval.pdf][Curvature Scale Space]]
*** Geometric Features for Shape Descriptors
**** average binding energy
**** eccentricity: measure of aspect ratio
**** circularity
**** ellipse variance
**** convexity
**** hole area ratio
*** Shape signatures
**** contour curvature
**** triangle area representation
** [[http://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html][When does deep learning work better than SVM or Random Forest]]
*** SVM more hyperparameters to tune
*** Random forest is simpler
*** Both grow with number of training data unlike parametric model
*** SVM useful for small datasets and fewer outliers. Super-quadratic training data
*** Random Forest requires more training data but robust. Linear with training data
*** Deep learning don't need worry about feature engineering
** [[https://www.researchgate.net/post/Is_random_forest_better_than_support_vector_machines][Is SVM better than Random Forest]]
*** Small number of classes with few outliers than SVM works well
*** Random forest need more training instances.
** [[https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms][What are advantages of different classfication algorithms ?]]
*** SVM
**** Painfully slow to train. Not useful for industry scale application
*** Tree Ensembles
**** Can handle data of varying scales better
**** Gradient Boosted Tree performs better but more tuning needed and prone to overfitting compared to Random Forest
**** Underperform when dimensionality is very high with respect to number of training 
** [[https://www.quora.com/When-should-I-use-Boosting-instead-of-SVM][When should I use boosting over SVM]]
*** Boosting is slow
*** Dense feature set = boosting
*** Sparse feature set = SVM
*** SVM does not handle class imbalance and assume training and test from same distribution
** Feature Descriptors Survey
*** [[http://www.jatit.org/volumes/Vol87No1/12Vol87No1.pdf][A Survey of Feature Extraction Techniques in Content-based Image Detection]]
**** [[https://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/tuytelaars_ijcv2004.pdf][EBR]]
**** [[https://www.researchgate.net/publication/221304077_Critical_Nets_and_Beta-Stable_Features_for_Image_Matching][Beta-stable features]]
**** FAST
**** AGHAST
**** [[https://gjacopo.github.io/imtools/feature/fastcpda.html][Fast CPDA]]
**** SURF is the best descriptor
**** Binary descriptor: BRISK, FREAK
*** [[http://www.ijarcce.com/upload/2016/april-16/IJARCCE%20126.pdf][A Brief History of Feature Detector]]
**** SIFT, SURF, HOG, MSER, BRISK, FREAK and ORB
*** [[http://www.ijser.org/researchpaper/A-Literature-Survey-of-Image-Descriptors-in-Content-Based-Image-Retrieval.pdf][Survey of Image Descriptor]]
**** Color descriptor
***** Dominant Color Descriptor (DCD)
***** Scalable Color Descriptor (SCD)
***** Color Structure Descriptor (CSD)
***** Color moment, color set, color histogram
**** Texture descriptor
***** Edge Histogram Descriptor (EHD)
***** Homogeneous Texture Descriptor (HTD)
**** Shape
***** Shape distribution
***** Fourier centroid histogram
*** [[https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A80C3E52CE3D92443DEF40EA44B82DE7/S2048770316000135a.pdf/div-class-title-a-survey-on-compact-features-for-visual-content-analysis-div.pdf][A survey on compact features for visual content analysis]]
**** Blob
***** [[http://www.cs.utexas.edu/~grauman/papers/bplr_CVPR2011.pdf][Boundary Preserving Dense Local Region (BPLR)]]
***** [[https://www.doc.ic.ac.uk/~ajd/Publications/alcantarilla_etal_eccv2012.pdf][KAZE]]
**** Keypoint descriptor
***** [[http://imagine.enpc.fr/~monasse/Stereo/Projects/TolaFuaLepetit08.pdf][DAISY]]
*** [[http://ocean.kisti.re.kr/downfile/volume/ieek/E1STIF/2016/v5n3/E1STIF_2016_v5n3_153.pdf][Recent advances in feature detectors]]
*** [[https://arxiv.org/pdf/1607.06178v1.pdf][Feature Descriptors for Tracking by Detection]]
**** Distinct: AKAZE and SIFT
**** BRISK or ORB less senstivie to change in scale compared to AKAZE
*** [[https://www.researchgate.net/publication/273841042_A_survey_of_recent_advances_in_visual_feature_detection][Survey of recent advances in visual feature detection]]
*** [[http://blog.annaphilips.com/feature-detectors-descriptors-opencv/][Feature Detectors and Descriptor in OpenCV]]
*** [[http://www.cnblogs.com/lvpengms/p/4122504.html][List of CV Projects]]
** Color descriptors
*** CS-LBP + Gabor for each component of HSV
*** variable kernel density estimation
**** arctan R/G, arctan B/G, normalized rgb
*** c1 = arctan(R / max(G, B))
*** c2 = arctan(G / max(R, B))
*** c3 = arctan(B / max(R, G))
*** o1 = (R - G) / 2
*** o2 = (R + G) / (4 - B/2)
*** Use Gaussian derivative on all these channels
*** Using Gaussian color model which can be converted from XYZ color space
*** SIFT for different power-law transform (different gamma)
*** m1 = canny edge on ln(R/G), ln (R/B), ln(G/B). Need to determine threshold to prevent break down at black point
*** RGB FREAK
*** any linear combination of RGB is illumination invariant for SIFT
*** O1 = (R - G) / sqrt(2), O2 = (R + G - 2B) / sqrt(6), O3 = R + G +B / sqrt(3)
*** Transformed color: R = (R - mean(R)) / std(R)
*** Color moment invariant
*** W1 = O1 / O3, W2 = O2 / O3
*** rgSIFT, OpponentSIFT, WSIFT
*** Quaternionic Weber Local Descriptor (QWLD)
*** quaternion-Michelson descriptor (QMD)
*** Color LBP
*** Those using SIFT works better than traditional method
*** Detecting salient cue using color ratio
**** Mask out low intensity value. (1/10 of maximum of the channel or sum of rgb must be 30)
**** get normalized r, g, b
**** r` = r / (3 * mean(r)), g` = g / (3 * mean(g)), b` = b / (3 * mean(b)) 
**** Convert to opponent color space R = R - (G + B)/2, G = G - (R + B)/2, B = B - (R+G)/2, Y = (R + G)/2 - |R - G| - B
**** Take ln(R/G) and ln(Y/B) to build spatial pyramid of 8 scales. 
**** Take difference of logarithm to construct saliency map
*** Color Invariant Signature
**** log chromacity color space: ln (R/G) and ln(B/G)
**** GMM to model color 
**** l1 = (R - G)^2 / ((R-G)^2 + (R-B)^2 + (G-B)^2)
**** l2 = (R - B)^2 / ((R-G)^2 + (R-B)^2 + (G-B)^2)
**** l3 = (G - B)^2 / ((R-G)^2 + (R-B)^2 + (G-B)^2)
** [[https://github.com/automl][Collection of AutoML repo]]
** [[http://www.ml4aad.org/][ML4AAD Source Codes]]
** Data Augmentation
*** [[https://github.com/iacopomasi/face_specific_augm][Do we really need to collect millions of faces ]]
** Robust Active Feature Selection
*** MIL inspired online boosting algorithm
*** Uses Haar-like feature
*** Maximizing Fischer information loss function online manner
*** Select weak classifier that maximizes positive bag and minimize negative bag
*** Sample samples around target
** Automatic Parameter Adaptation for Multiple-Object Tracking
*** Learn contextual feature which influence tracking quality to learn appropriate parameters offline
*** Contextual feature
**** Density of mobile objects
**** Occlusion level of mobile objects
**** Contrast of mobile object
**** Contrast variance of mobile object
**** 2D area of mobile objects
**** 2D area variance of mobile objects
*** Learn context cluster
*** Parameter change when context change
** Color Model Selection and Adaptation in Dynamic Scene
*** Gaussian Mixture Model of HS space 
*** Model background besides the object to be tracked
*** Adaptive color mixture model
** Dynamic Feature Selection Processes
*** Adaptive Color Tracking System
**** adaptive correlation filter from multi-channel color
**** use a set of 10 color names for each pixel in target box 
** Automatic Tracker Selection wrt Object Detection Performance
*** Use the following features
**** 2D area, 2D aspect ratio -> for object with different size
**** color covariance when lighting is not good
**** color histogram and dominant color when lighting is good
**** weightd combination of these features similarities
**** Evaluate tracker based on predicted objects
* Mar: Week 11: *27-2*
** Augmentation
*** [[https://arxiv.org/pdf/1703.03702.pdf][Data Driven Color Augmentation]]
**** Illumination estimation using shade of grey on different images. Apply transformation on color corrected image to color cast.
**** Apply random gamma correction with factor [0 - 2]
**** Blurring image with varying sigma
*** Fancy PCA
*** Color Jittering
*** Contrast manipulation
*** Flicker generation
*** Haze generation
*** [[http://pure.qub.ac.uk/portal/files/16612194/AMMDS_camera_ready_v2.pdf][Data Augmentation for Person Re-identification]]
**** Randomly add value to Hue Channel
**** Replace background
** Ground truth generation
*** Shadow
*** Flicker
*** Low contrast / blur / haze
*** Dark
*** Bright
** AutoML
*** [[https://github.com/automl/HPOlib][HPOlib combines spearmint, smac and hyperopt]]
*** [[https://github.com/automl/SMAC3][SMAC]]
*** [[https://github.com/automl/RoBO][Robust Bayesian Optimization Framework]]
*** [[https://github.com/automl/auto-sklearn][Auto sklearn]]
*** [[http://scikit-learn.org/stable/modules/feature_selection.html][Sklearn feature selection]]
*** Selecting best preprocessing parameters
*** Selecting best features
*** Selecting best models
*** Change parameters based on context (Online)
*** [[https://github.com/rhiever/tpot][TPOT Data Science Assistant]]
** Adaptive Tracking
*** [[www.nicta.com.au/pub?doc=5132][Real Time Tracking compressive sensing]]
*** [[http://www4.comp.polyu.edu.hk/~cslzhang/paper/AFS.pdf][Robust Object Tracking via Active Feature Selection]]
*** [[https://www.eecs.qmul.ac.uk/~andrea/papers/2016_ECCVW_MOT_OnlineMTTwithStrongAndWeakDetections_Sanchez-Matilla_Poiesi_Cavallaro.pdf][Online Multi-target tracking using strong and weak detection]]
*** [[http://or.nsfc.gov.cn/bitstream/00001903-5/98246/1/1000008745384.pdf][Online Discriminative Structured Output SVM]]
*** [[http://www.robots.ox.ac.uk/~tvg/publications/2015/struck-author.pdf][Structured Output Tracking with Kernels (STRUCK)]]
**** [[https://github.com/gnebehay/STRUCK][Source Code]]
*** [[https://pdfs.semanticscholar.org/fe2a/aad872a2cf08c09dd52ca972f323666306db.pdf][Sparsity based Collaborative (SCM)]]
*** [[http://faculty.ucmerced.edu/mhyang/project/cvpr12_jia_project.htm][Visual Tracking via Adaptive Structural Local Sparse Appearance Model]] (ASLA)
*** [[https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/][Learning Spatially Regularized Correlation Filter (SRCF)]]
*** [[https://arxiv.org/pdf/1507.08085.pdf][Edge Box Tracker (EBT) ]]
**** Does not assume previous detection is accurate and trajectory is smooth
**** Search scheme: window search, particle search (random sampling blind to spatial and edge), hard negatives (learn background and foreground online) 
**** Linear combination of proposal score and detector score
**** Motion model, observation model and model update model
**** Current frame processed into edge map and use instance specific proposal 
**** Proposals consists of : edge proposed and sampling around previous location in radius. Better to use those proposed by edge box only
**** Using edge and sampled region as negative support vector
**** Uses structured output svm to re-rank proposals because edge box miss cluttered background
*** [[http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Hua_Online_Object_Tracking_ICCV_2015_paper.pdf][Simplified Proposal Selection Tracker]] (sPST)
**** One positive sample using HOG
**** 50& bounding box overlap hard negative mining from the frame
**** Evaluated at diffrent scales 
**** Using hough transform voting from optical flow correspondance next frame
**** Score proposal using object edgeness (edge box)
**** Consists of 5 top detector proposals and 5 top geometry estimated proposals
**** Using new object proposals as positive examples
*** [[https://arxiv.org/pdf/1404.7584.pdf][High Speed Tracking with Kernelized Correlation Filter]] (KCF)
*** [[https://www.ri.cmu.edu/pub_files/2013/0/2013_ICCV_Kiani.pdf][Multi-channel Correlation Filter]] (MCCF)
*** [[http://www.cs.colostate.edu/~draper/papers/bolme_cvpr10.pdf][Visual Object Tracking with Adaptive Correlation Filter (MOSSE)]]
*** [[http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Possegger_In_Defense_of_2015_CVPR_paper.pdf][In Defense of Color-based model free tracking]]
**** Distinguish object from current surrounding background
**** Reduce risk of drifting towards region of similar appearance
**** Bayes classfier on target object and its surrounding
**** Train model of object distractor and object surrounding
**** Weight with distance from previous object location
**** Scale estimation
** Object recognition
*** [[https://pdollar.github.io/files/papers/DollarPAMI14pyramids.pdf][ACF Detector]]
*** [[https://pdollar.github.io/files/papers/DollarBMVC09ChnFtrs.pdf][Integral Channel Feature]]
*** [[https://pdfs.semanticscholar.org/4f23/a446f1f15d0ac65e4e50232531f8eb404a7b.pdf][Pedestrian Detection at 100 fps]]
*** [[http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf][Histogram of Oriented Gradient for Human Detection]]
*** [[https://cs.brown.edu/~pff/papers/lsvm-pami.pdf][Deformable Part Model (DPM)]]
*** Region Covariance descriptor
** Using Saliency as proposal or feature
** Including prior 

